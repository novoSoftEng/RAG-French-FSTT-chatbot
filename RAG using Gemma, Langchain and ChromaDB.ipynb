{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc264e7-e200-46a0-9ffd-267c3077e1b8",
   "metadata": {},
   "source": [
    "### Procedure\n",
    "We create two classes:\n",
    "\n",
    "- **AIAgent** :  An AI Agent that query Gemma LLM using a custom prompt that instruct Gemma to generate and answer (from the query) by refering to the context (as well provided); the answer to the AI Agent query function is then returned.\n",
    "\n",
    "- **RAGSystem** :  initialized with the dataset with Data Science information, with an AIAgent object. In the init function of this class, we ingest the data from the dataset in the vector database. This class have as well a query member function. In this function we first perform similarity search with the query to the vector database. Then, we call the generate function of the ai agent object. Before returning the answer, we use a predefined template to compose the overal response from the question, answer and the context retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d3adb-ea7a-4e5b-9fc9-49b5bdf8804c",
   "metadata": {},
   "source": [
    "## Packages instalation and configurations : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8cf6277-9832-432e-adfa-f64393cdbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdb94a-57f3-4126-a832-09fdd41b5680",
   "metadata": {},
   "source": [
    "## AI Agent class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c1da1a-62b7-4015-bf72-0bae46815994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set your Hugging Face API token\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a573a73-fe8a-4dff-9380-fadeb5cf872e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class AIAgent:\n",
    "    \n",
    "    def __init__(self, model_name=\"aymanboufarhi/gemma2B-chat-bot-fstt\", max_length=1000):\n",
    "        self.max_length = max_length\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "            self.gemma_llm = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading model: {e}\")\n",
    "\n",
    "    def create_prompt(self, query, context):\n",
    "        # Prompt template\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI Agent specialized to answer questions about FSTT (faculty of science and technology in Tanger).\n",
    "        Explain the concept or answer the question about FSTT.\n",
    "        In order to create the answer,use the information from the context if it seems to be relevant to the question provided (Context). \n",
    "        and the context will be as a list, so you must use just the most relevent informations from the list.\n",
    "        Answer with simple words.\n",
    "        If needed, include also explanations.\n",
    "        it's important to answer with french languge.\n",
    "        return only the answer\n",
    "        Question: {query}\n",
    "        Context: {context}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def generate(self, query, retrieved_info):\n",
    "        prompt = self.create_prompt(query, retrieved_info)\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        # Answer generation\n",
    "        answer_ids = self.gemma_llm.generate(input_ids, max_new_tokens=self.max_length)\n",
    "        \n",
    "        # Decode and return the answer\n",
    "        answer = self.tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189c880-7e57-468f-bf1f-72b2a28570d7",
   "metadata": {},
   "source": [
    "### Test the AIAgent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d61f2a-0b34-4b07-8d3f-c100d35984fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idriss/.local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/idriss/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56859836dddf45ca96bbaa4968e89aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the AI Agent\n",
    "ai_agent = AIAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08aea186-4cef-4c3a-acef-f4456d081588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"Sentence embedding based Retrieval Based Augmented generation.\n",
    "       Given a ChromaDB collection, retriever finds num_retrieved_docs relevant documents.\"\"\"\n",
    "    \n",
    "    def __init__(self, ai_agent, collection, num_retrieved_docs=5):\n",
    "        self.num_docs = num_retrieved_docs\n",
    "        self.collection = collection\n",
    "        self.ai_agent = ai_agent\n",
    "    \n",
    "    def retrieve(self, query):\n",
    "        # Retrieve top k similar documents to query\n",
    "        results = self.collection.query(query_texts=[query], n_results=self.num_docs)\n",
    "        docs = [result for result in results['documents']]\n",
    "        return docs\n",
    "    \n",
    "    def query(self, query):\n",
    "        # Generate the answer\n",
    "        context_docs = self.retrieve(query)\n",
    "        context_docs = context_docs[0]\n",
    "        print(context_docs)\n",
    "        \n",
    "        answer = self.ai_agent.generate(query, context_docs)\n",
    "        \n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee2eceba-e753-4942-ae17-5d29bf107202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_from_text(text):\n",
    "    answer_match = re.search(r'Answer:\\s*(.*)', text, re.DOTALL)\n",
    "    answer = answer_match.group(1).strip() if answer_match else \"\"\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de12a7d1-0cb0-4f3c-8c82-29d87bcf7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Configure the ChromaDB client with persistence\n",
    "persist_directory = \"/home/idriss/Desktop/chroma_db\"\n",
    "client2 = chromadb.PersistentClient(path=persist_directory)\n",
    "collection = client2.get_collection(name=\"text_embeddings\")\n",
    "\n",
    "# Initialize the RAGSystem with the existing collection\n",
    "rag_system = RAGSystem(ai_agent=ai_agent, collection=collection, num_retrieved_docs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae35372f-cafc-4a73-a24e-64f4b6145688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['le nom du doyen de fstt est  pr.mustapha diani', 'nom du club : club les sophistes | description du club  : https://www.facebook.com/sophistesfstt | lien du club : https://fstt.ac.ma/portail2023/club-les-sophistes/', 'les nom de tout les departement dand fstt : génie informatique | génie chimique | sciences de la terre | génie mécanique | sciences de la vie | génie electrique | tec | physique | mathématiques', 'fstt = fst tanger = faculté des sciences et techniques de tanger']\n",
      "Donne les noms de tous les departements de FSTT.\n",
      "        Réponse: Le FSTT compte 10 departements. They sont : Génie Informatique, Génie Chimique, Sciences de la Terre, Génie Mécanique, Sciences de la Vie, Génie Électrique, Technique et Physique, Mathématiques et Applications, et Economie et Management.\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query1 = \"donner moi le nom de Doyen de FSTT\"\n",
    "query2 = \"donner moi les noms de tout les departements de fstt\"\n",
    "query3 = \"donner moi les noms de tout les clubs de fstt\"\n",
    "query4 = \"c'est quoi fstt?\"\n",
    "query5 = \"dooner moi quelque information sur le departement GÉNIE INFORMATIQUE\"\n",
    "query6 = \"Donne le nombre de départements avec les informations de chaque departement\"\n",
    "query7 = \"donner moi des informations sur MST : Intelligence Artificielle et Sciences de Données\"\n",
    "query8 = \"donner moi le nom de Coordinnateur de departement GÉNIE INFORMATIQUE\"\n",
    "query9 = \"quels sont les diplômes de FST Tanger ?\"\n",
    "query9 = \"donner moi le programme de formation de master : Intelligence Artificielle et Sciences de Données\"\n",
    "query10 = \"le nombre des departement\"\n",
    "\n",
    "# Get the answer from the RAG system\n",
    "response = rag_system.query(query2)\n",
    "\n",
    "# Print the response\n",
    "# display(Markdown(response))\n",
    "print(extract_answer_from_text(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "877361a6-f0ca-48c2-beff-07ed314474ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['le nom du doyen de fstt est  pr.mustapha diani', 'fstt = fst tanger = faculté des sciences et techniques de tanger', \"présentation générale sur fst tanger :  faculté des sciences et techniques tanger : ( fst tanger ou fstt tanger ), est un établissement universitaire à caractère scientifique et technique, la fst est destinée à s'intégrer dans le pôle technologique et industriel de la région pour être une pépinière de techniciens et de cadres de haut niveau capables de servir de courroie de transmission entre le technicien supérieur et l'ingénieur concepteur.      créée en 1995, la fst de tanger est un des huit établissements de l université abdelmalek essaâdi. elle regroupe actuellement une trentaine de programmes d'études repartis sur quatre cycles offerts par neuf  départements : sciences de la vie, sciences de la terre, génie chimique, physique, mathématiques, génie informatique, génie electrique et génie mécanique et  de langues.    derrière ses programmes d enseignement et de recherche, totalement inscrits dans le courant actuel des sciences et techniques, la fst de tanger compte avec un corps professoral, jeune et performant, de 151  enseignants chercheurs et un staff veillant de 55 administratifs. avec ses stages, sa formation pratique, son lien serré avec son environnement socio-économique, la fst de tanger offre une formation adaptée, un encadrement personnalisé et est à l'écoute des besoins des étudiants. un service des stages est également à la disposition des étudiants.  avec son lien serré avec son environnement socio-économique la fst de tanger offre une formation pratique et adaptée, un encadrement personnalisé et est à l écoute des besoins des étudiants. un service des stages est également à la disposition des étudiants.\", 'titre de post ou article : formations avancées en ligne de l académie de l ompi, première session, 2024 | contenu post ou article : l organisation mondiale de la propriété intellectuelle (ompi), lance des formations avancées en ligne au profit des industriels, enseignants, chercheurs, administrateurs, doctorants et inventeurs. la première session de l année 2024 concerne les différents outils du système de la propriété intellectuelle, destinées pour la communauté des membres du réseau tisc au maroc. ces formations sanctionnées par un certificat délivré par l ompi seront animées par des experts internationaux en la matière.   quant aux étudiants, ils peuvent s inscrire au cours dl-101 ouvert toute l année à https://welc.wipo.int/acc/index.jsf…   dernier délai d inscription est le 15 mars 2024. | lien de post ou article : https://fstt.ac.ma/portail2023/formations-avancees-en-ligne-de-lacademie-de-lompi-premiere-session-2024/']\n",
      "FSTT est la Faculté des Sciences et Techniques de Tanger. C'est un établissement universitaire à but scientifique et technique, la FSTT est destinée à s'intégrer dans le pôle technologique et industriel de la région pour être une pépinière de techniciens et de cadres de haut niveau.\n"
     ]
    }
   ],
   "source": [
    "# Get the answer from the RAG system\n",
    "response = rag_system.query(query4)\n",
    "print(extract_answer_from_text(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bed8e4-f7c2-4fca-a310-97ae8c3d3613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7618c7b9-4c4b-41bf-8ac9-99cf1640036e",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/code/gpreda/rag-using-gemma-langchain-and-chromadb#AI-Agent-class\n",
    "- https://huggingface.co/aymanboufarhi/gemma2B-chat-bot-fstt/tree/main\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
